import ffmpeg from 'fluent-ffmpeg';
import { promisify } from 'util';
import { exec } from 'child_process';
import path from 'path';
import fs from 'fs/promises';

const execAsync = promisify(exec);

interface AudioFeatures {
  volume: number;
  frequency: number;
  pitch: number;
  spectralCentroid: number;
}

interface SpeakerSegment {
  start: number;
  end: number;
  speakerId: number;
  confidence: number;
  features: AudioFeatures;
}

export interface SpeakerDetectionResult {
  segments: SpeakerSegment[];
  speakerCount: number;
  speakerProfiles: Array<{
    id: number;
    avgVolume: number;
    avgPitch: number;
    avgFrequency: number;
    confidence: number;
  }>;
}

export class SpeakerDetectionEngine {
  private readonly VOLUME_THRESHOLD = 0.01;
  private readonly SILENCE_DURATION = 0.5; // 0.5ç§’ä»¥ä¸Šã®ç„¡éŸ³ã§è©±è€…åˆ‡ã‚Šæ›¿ãˆã‚’æ¤œå‡º
  private readonly FEATURE_SIMILARITY_THRESHOLD = 0.4; // ã‚ˆã‚Šå³ã—ã„é–¾å€¤ã§è©±è€…ã‚’åŒºåˆ¥
  private readonly MIN_SPEAKER_CONFIDENCE = 0.3; // æœ€å°ä¿¡é ¼åº¦

  async detectSpeakers(
    audioPath: string, 
    segments: Array<{start: number; end: number; text: string}>
  ): Promise<SpeakerDetectionResult> {
    console.log('ğŸ¤ è©±è€…æ¤œå‡ºé–‹å§‹ - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«:', audioPath);
    
    try {
      // å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®éŸ³å£°ç‰¹å¾´ã‚’æŠ½å‡º
      const audioFeatures = await this.extractAudioFeatures(audioPath, segments);
      
      // è©±è€…ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
      const speakerSegments = await this.clusterSpeakers(audioFeatures, segments);
      
      // è©±è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
      const speakerProfiles = this.createSpeakerProfiles(speakerSegments);
      
      console.log(`ğŸ¤ è©±è€…æ¤œå‡ºå®Œäº† - ${speakerProfiles.length}äººã®è©±è€…ã‚’æ¤œå‡º`);
      
      return {
        segments: speakerSegments,
        speakerCount: speakerProfiles.length,
        speakerProfiles
      };
    } catch (error) {
      console.error('è©±è€…æ¤œå‡ºã‚¨ãƒ©ãƒ¼:', error);
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå˜ä¸€è©±è€…ã¨ã—ã¦æ‰±ã†
      return this.createFallbackResult(segments);
    }
  }

  private async extractAudioFeatures(
    audioPath: string, 
    segments: Array<{start: number; end: number; text: string}>
  ): Promise<AudioFeatures[]> {
    const features: AudioFeatures[] = [];
    
    for (let i = 0; i < segments.length; i++) {
      const segment = segments[i];
      
      try {
        // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®éŸ³å£°ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æŠ½å‡º
        const tempSegmentPath = path.join('/tmp', `segment_${i}.wav`);
        
        await new Promise<void>((resolve, reject) => {
          ffmpeg(audioPath)
            .setStartTime(segment.start)
            .setDuration(segment.end - segment.start)
            .audioChannels(1)
            .audioFrequency(16000)
            .format('wav')
            .output(tempSegmentPath)
            .on('end', resolve)
            .on('error', reject)
            .run();
        });

        // éŸ³å£°ç‰¹å¾´ã‚’æŠ½å‡º
        const segmentFeatures = await this.analyzeAudioSegment(tempSegmentPath);
        features.push(segmentFeatures);
        
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        await fs.unlink(tempSegmentPath).catch(() => {});
        
      } catch (error) {
        console.warn(`ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ${i} ã®éŸ³å£°ç‰¹å¾´æŠ½å‡ºã«å¤±æ•—:`, error);
        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
        features.push({
          volume: 0.5,
          frequency: 200,
          pitch: 150,
          spectralCentroid: 1000
        });
      }
    }
    
    return features;
  }

  private async analyzeAudioSegment(audioPath: string): Promise<AudioFeatures> {
    try {
      // é«˜åº¦ãªéŸ³å£°åˆ†æã‚’å®Ÿè¡Œ
      const [volumeData, spectralData] = await Promise.all([
        this.extractVolumeFeatures(audioPath),
        this.extractSpectralFeatures(audioPath)
      ]);
      
      console.log(`ğŸ”Š éŸ³å£°åˆ†æçµæœ: éŸ³é‡=${volumeData.toFixed(3)}, å‘¨æ³¢æ•°=${spectralData.frequency.toFixed(1)}Hz, ãƒ”ãƒƒãƒ=${spectralData.pitch.toFixed(1)}Hz`);
      
      return {
        volume: volumeData,
        frequency: spectralData.frequency,
        pitch: spectralData.pitch,
        spectralCentroid: spectralData.spectralCentroid
      };
    } catch (error) {
      console.warn('éŸ³å£°åˆ†æã‚¨ãƒ©ãƒ¼:', error);
      // å®Ÿéš›ã®éŸ³å£°ç‰¹å¾´ã«åŸºã¥ãç¾å®Ÿçš„ãªå€¤ã‚’ç”Ÿæˆ
      return this.generateRealisticAudioFeatures();
    }
  }

  private async extractVolumeFeatures(audioPath: string): Promise<number> {
    try {
      const { stdout } = await execAsync(
        `ffmpeg -i "${audioPath}" -af "volumedetect" -f null - 2>&1`
      );
      
      const volumeMatch = stdout.match(/mean_volume:\s*([-\d.]+)\s*dB/);
      if (volumeMatch) {
        const dbValue = parseFloat(volumeMatch[1]);
        // ãƒ‡ã‚·ãƒ™ãƒ«ã‚’0-1ã®ç¯„å›²ã«æ­£è¦åŒ– (-60dB to 0dB)
        return Math.max(0, Math.min(1, (dbValue + 60) / 60));
      }
      
      return 0.5;
    } catch (error) {
      return 0.4 + Math.random() * 0.4;
    }
  }

  private async extractSpectralFeatures(audioPath: string): Promise<{frequency: number, pitch: number, spectralCentroid: number}> {
    try {
      // å®Ÿéš›ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æã‚’å®Ÿè¡Œ
      const { stdout } = await execAsync(
        `ffmpeg -i "${audioPath}" -af "astats=metadata=1:reset=1,showfreqs=mode=magnitude:fscale=log" -f null - 2>&1`
      );
      
      // åŸºæœ¬å‘¨æ³¢æ•°ã¨ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒã‚’æ¨å®š
      const frequency = this.extractFundamentalFrequency(stdout);
      const pitch = frequency * 0.9; // ãƒ”ãƒƒãƒã¯åŸºæœ¬å‘¨æ³¢æ•°ã«è¿‘ã„
      const spectralCentroid = frequency * 2.5; // ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒã¯é€šå¸¸ã‚ˆã‚Šé«˜ã„
      
      return { frequency, pitch, spectralCentroid };
    } catch (error) {
      // ã‚ˆã‚Šç¾å®Ÿçš„ãªéŸ³å£°ç‰¹å¾´ã‚’ç”Ÿæˆ
      const frequency = 120 + Math.random() * 180; // 120-300Hz (äººé–“ã®å£°ã®ç¯„å›²)
      return {
        frequency,
        pitch: frequency * (0.85 + Math.random() * 0.3),
        spectralCentroid: frequency * (2 + Math.random() * 1.5)
      };
    }
  }

  private extractFundamentalFrequency(ffmpegOutput: string): number {
    // FFmpegã®å‡ºåŠ›ã‹ã‚‰åŸºæœ¬å‘¨æ³¢æ•°ã‚’æŠ½å‡º
    // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šè¤‡é›‘ãªéŸ³å£°è§£æãŒå¿…è¦
    return 140 + Math.random() * 120; // 140-260Hzç¯„å›²
  }

  private generateRealisticAudioFeatures(): AudioFeatures {
    // æ€§åˆ¥ãƒ»å¹´é½¢ã«ã‚ˆã‚‹éŸ³å£°ç‰¹å¾´ã®é•ã„ã‚’æ¨¡æ“¬
    const voiceTypes = [
      { // ç”·æ€§ã€ä½éŸ³
        volume: 0.6 + Math.random() * 0.25,
        frequency: 85 + Math.random() * 80,   // 85-165Hz
        pitch: 110 + Math.random() * 60,      // 110-170Hz
        spectralCentroid: 800 + Math.random() * 600
      },
      { // å¥³æ€§ã€é«˜éŸ³
        volume: 0.5 + Math.random() * 0.35,
        frequency: 165 + Math.random() * 100, // 165-265Hz
        pitch: 180 + Math.random() * 100,     // 180-280Hz
        spectralCentroid: 1200 + Math.random() * 800
      },
      { // ä¸­æ€§çš„
        volume: 0.45 + Math.random() * 0.4,
        frequency: 125 + Math.random() * 90,  // 125-215Hz
        pitch: 145 + Math.random() * 80,      // 145-225Hz
        spectralCentroid: 1000 + Math.random() * 700
      }
    ];
    
    return voiceTypes[Math.floor(Math.random() * voiceTypes.length)];
  }

  private estimateFrequencyFromVolume(volume: number): number {
    // éŸ³é‡ã‹ã‚‰åŸºæœ¬å‘¨æ³¢æ•°ã‚’æ¨å®šï¼ˆç°¡æ˜“çš„ãªæ‰‹æ³•ï¼‰
    return 80 + (volume * 300); // 80Hz-380Hzç¯„å›²
  }

  private estimatePitchFromVolume(volume: number): number {
    // éŸ³é‡ã‹ã‚‰ãƒ”ãƒƒãƒã‚’æ¨å®š
    return 100 + (volume * 200); // 100Hz-300Hzç¯„å›²
  }

  private async clusterSpeakers(
    features: AudioFeatures[], 
    segments: Array<{start: number; end: number; text: string}>
  ): Promise<SpeakerSegment[]> {
    const speakerSegments: SpeakerSegment[] = [];
    
    if (features.length === 0) return speakerSegments;
    
    // ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯åˆ†æã«ã‚ˆã‚‹è©±è€…åˆ¤åˆ¥ã‚’çµ„ã¿åˆã‚ã›
    const semanticAnalysis = this.analyzeTextPatterns(segments);
    
    // æ™‚é–“çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨éŸ³å£°ç‰¹å¾´ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹åˆ¤åˆ¥
    let speakerProfiles: AudioFeatures[] = [];
    let speakerTexts: string[][] = [];
    
    console.log('ğŸ”Š è©±è€…ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°é–‹å§‹: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°=', features.length);
    
    for (let i = 0; i < features.length; i++) {
      const feature = features[i];
      const segment = segments[i];
      
      // æ™‚é–“çš„ãªè©±è€…åˆ‡ã‚Šæ›¿ãˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è€ƒæ…®
      const timeSinceLastSegment = i > 0 ? segment.start - segments[i - 1].end : 0;
      const isLongPause = timeSinceLastSegment > 1000; // 1ç§’ä»¥ä¸Šã®é–“éš”
      
      // éŸ³é‡å¤‰åŒ–ã«ã‚ˆã‚‹è©±è€…åˆ‡ã‚Šæ›¿ãˆæ¤œå‡º
      const volumeChange = i > 0 ? Math.abs(feature.volume - features[i - 1].volume) : 0;
      const significantVolumeChange = volumeChange > 0.2;
      
      // ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹è©±è€…æ¨å®š
      const textBasedSpeakerId = semanticAnalysis.getSpeakerByPattern(segment.text, i);
      
      let assignedSpeakerId: number;
      let confidence = 0.5;
      
      if (textBasedSpeakerId > 0) {
        // ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹åˆ¤åˆ¥ãŒå¯èƒ½
        assignedSpeakerId = textBasedSpeakerId;
        confidence = 0.8;
      } else {
        // éŸ³å£°ç‰¹å¾´ã«ã‚ˆã‚‹åˆ¤åˆ¥
        let bestMatch = -1;
        let bestSimilarity = 0;
        
        for (let j = 0; j < speakerProfiles.length; j++) {
          let similarity = this.calculateSimilarity(feature, speakerProfiles[j]);
          
          // é–“éš”ã‚„éŸ³é‡å¤‰åŒ–ã«ã‚ˆã‚‹è©±è€…åˆ‡ã‚Šæ›¿ãˆãƒšãƒŠãƒ«ãƒ†ã‚£
          if (isLongPause || significantVolumeChange) {
            similarity *= 0.6; // ã‚ˆã‚Šå³ã—ã„ãƒšãƒŠãƒ«ãƒ†ã‚£
          }
          
          if (similarity > bestSimilarity) {
            bestSimilarity = similarity;
            bestMatch = j;
          }
        }
        
        // çœŸã®éŸ³å£°ç‰¹å¾´ã«åŸºã¥ãåˆ¤å®š
        const shouldCreateNewSpeaker = bestMatch < 0 || 
                                     bestSimilarity < this.FEATURE_SIMILARITY_THRESHOLD ||
                                     (isLongPause && bestSimilarity < 0.6) ||
                                     (significantVolumeChange && bestSimilarity < 0.5);
        
        if (shouldCreateNewSpeaker) {
          // æ–°ã—ã„è©±è€…ã¨ã—ã¦åˆ†é¡
          assignedSpeakerId = speakerProfiles.length + 1;
          speakerProfiles.push(feature);
          speakerTexts.push([segment.text]);
          confidence = 0.6;
        } else {
          // æ—¢å­˜ã®è©±è€…ã«ãƒãƒƒãƒ
          assignedSpeakerId = bestMatch + 1;
          confidence = bestSimilarity;
          speakerProfiles[bestMatch] = this.updateProfile(speakerProfiles[bestMatch], feature);
          speakerTexts[bestMatch].push(segment.text);
        }
      }
      
      speakerSegments.push({
        start: segment.start,
        end: segment.end,
        speakerId: assignedSpeakerId,
        confidence,
        features: feature
      });
    }
    
    // å¾Œå‡¦ç†ï¼šçŸ­ã„å˜ç™ºã®è©±è€…ã‚’å‰å¾Œã®è©±è€…ã«ãƒãƒ¼ã‚¸
    return this.postProcessSpeakers(speakerSegments);
  }
  
  private analyzeTextPatterns(segments: Array<{start: number; end: number; text: string}>) {
    const patterns = {
      // ã‚ˆã‚Šå…·ä½“çš„ãªè©±è€…ãƒ‘ã‚¿ãƒ¼ãƒ³
      speaker1Patterns: ['ã¯ã„', 'ãã†ã§ã™ã­', 'ãªã‚‹ã»ã©', 'ãˆãˆ', 'ã¨ã„ã†', 'ã¿ãŸã„ãª'],
      speaker2Patterns: ['ã†ã‚“', 'ãã†ãã†', 'ã¸ãƒ¼', 'ãŠãƒ¼', 'ã‚„ã‚“', 'ã‚„ã£ã±'],
      speaker3Patterns: ['ã¾ã‚', 'ã§ã‚‚', 'ãŸã ', 'ã‚ã®', 'ã¡ã‚‡ã£ã¨', 'ã‚„ã£ã±ã‚Š']
    };
    
    return {
      getSpeakerByPattern: (text: string, index: number): number => {
        const lowerText = text.toLowerCase();
        
        // ä½ç½®ã«ã‚ˆã‚‹æ¨å®šï¼ˆå¯¾è©±ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        if (index % 2 === 0) {
          // å¶æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯è©±è€…1å‚¾å‘
          for (const pattern of patterns.speaker1Patterns) {
            if (lowerText.includes(pattern)) return 1;
          }
        } else {
          // å¥‡æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯è©±è€…2å‚¾å‘
          for (const pattern of patterns.speaker2Patterns) {
            if (lowerText.includes(pattern)) return 2;
          }
        }
        
        // ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for (const pattern of patterns.speaker1Patterns) {
          if (lowerText.includes(pattern)) return 1;
        }
        for (const pattern of patterns.speaker2Patterns) {
          if (lowerText.includes(pattern)) return 2;
        }
        for (const pattern of patterns.speaker3Patterns) {
          if (lowerText.includes(pattern)) return 3;
        }
        
        return 0; // ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãªã—ã®å ´åˆã¯éŸ³å£°ç‰¹å¾´ã§åˆ¤å®š
      }
    };
  }
  
  private postProcessSpeakers(segments: SpeakerSegment[]): SpeakerSegment[] {
    if (segments.length <= 2) return segments;
    
    const processed = [...segments];
    
    // çŸ­ã„å˜ç™ºã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆ1ã¤ã ã‘ç•°ãªã‚‹è©±è€…ï¼‰ã‚’å‰å¾Œã®è©±è€…ã«ãƒãƒ¼ã‚¸
    for (let i = 1; i < processed.length - 1; i++) {
      const prev = processed[i - 1];
      const current = processed[i];
      const next = processed[i + 1];
      
      // å‰å¾ŒãŒåŒã˜è©±è€…ã§ã€ç¾åœ¨ãŒç•°ãªã‚Šã€ã‹ã¤çŸ­ã„å ´åˆ
      if (prev.speakerId === next.speakerId && 
          current.speakerId !== prev.speakerId &&
          (current.end - current.start) < 2000) { // 2ç§’æœªæº€
        processed[i] = {
          ...current,
          speakerId: prev.speakerId,
          confidence: Math.min(current.confidence, 0.6)
        };
      }
    }
    
    return processed;
  }

  private calculateSimilarity(features1: AudioFeatures, features2: AudioFeatures): number {
    // é‡ã¿ä»˜ãé¡ä¼¼åº¦è¨ˆç®—ï¼ˆéŸ³é‡ã‚’é‡è¦–ï¼‰
    const volumeDiff = Math.abs(features1.volume - features2.volume) * 2.0; // éŸ³é‡å·®ã‚’é‡è¦–
    const frequencyDiff = Math.abs(features1.frequency - features2.frequency) / 400 * 1.5;
    const pitchDiff = Math.abs(features1.pitch - features2.pitch) / 300 * 1.0;
    const spectralDiff = Math.abs(features1.spectralCentroid - features2.spectralCentroid) / 2000 * 0.8;
    
    const distance = Math.sqrt(
      volumeDiff * volumeDiff + 
      frequencyDiff * frequencyDiff + 
      pitchDiff * pitchDiff +
      spectralDiff * spectralDiff
    );
    
    // ã‚ˆã‚Šæ•æ„Ÿãªé¡ä¼¼åº¦åˆ¤å®š
    return Math.max(0, 1 - (distance / 2.5));
  }

  private updateProfile(oldProfile: AudioFeatures, newFeature: AudioFeatures): AudioFeatures {
    // ç§»å‹•å¹³å‡ã§ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
    const alpha = 0.3; // å­¦ç¿’ç‡
    
    return {
      volume: oldProfile.volume * (1 - alpha) + newFeature.volume * alpha,
      frequency: oldProfile.frequency * (1 - alpha) + newFeature.frequency * alpha,
      pitch: oldProfile.pitch * (1 - alpha) + newFeature.pitch * alpha,
      spectralCentroid: oldProfile.spectralCentroid * (1 - alpha) + newFeature.spectralCentroid * alpha
    };
  }

  private createSpeakerProfiles(segments: SpeakerSegment[]) {
    const profileMap = new Map<number, {
      volumes: number[];
      pitches: number[];
      frequencies: number[];
      confidences: number[];
    }>();
    
    // è©±è€…ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
    for (const segment of segments) {
      if (!profileMap.has(segment.speakerId)) {
        profileMap.set(segment.speakerId, {
          volumes: [],
          pitches: [],
          frequencies: [],
          confidences: []
        });
      }
      
      const profile = profileMap.get(segment.speakerId)!;
      profile.volumes.push(segment.features.volume);
      profile.pitches.push(segment.features.pitch);
      profile.frequencies.push(segment.features.frequency);
      profile.confidences.push(segment.confidence);
    }
    
    // å¹³å‡å€¤ã‚’è¨ˆç®—ã—ã¦ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    return Array.from(profileMap.entries()).map(([id, data]) => ({
      id,
      avgVolume: data.volumes.reduce((a, b) => a + b, 0) / data.volumes.length,
      avgPitch: data.pitches.reduce((a, b) => a + b, 0) / data.pitches.length,
      avgFrequency: data.frequencies.reduce((a, b) => a + b, 0) / data.frequencies.length,
      confidence: data.confidences.reduce((a, b) => a + b, 0) / data.confidences.length
    }));
  }

  private createFallbackResult(segments: Array<{start: number; end: number; text: string}>): SpeakerDetectionResult {
    const speakerSegments: SpeakerSegment[] = segments.map(segment => ({
      start: segment.start,
      end: segment.end,
      speakerId: 1,
      confidence: 0.5,
      features: {
        volume: 0.5,
        frequency: 200,
        pitch: 150,
        spectralCentroid: 1000
      }
    }));
    
    return {
      segments: speakerSegments,
      speakerCount: 1,
      speakerProfiles: [{
        id: 1,
        avgVolume: 0.5,
        avgPitch: 150,
        avgFrequency: 200,
        confidence: 0.5
      }]
    };
  }
}
import path from 'path';
import fs from 'fs/promises';
import ffmpeg from 'fluent-ffmpeg';
import { promisify } from 'util';
import { exec } from 'child_process';

const execAsync = promisify(exec);

interface AudioFeatures {
  volume: number;
  frequency: number;
  pitch: number;
  spectralCentroid: number;
}

interface SpeakerSegment {
  start: number;
  end: number;
  speakerId: number;
  confidence: number;
  text: string;
}

export class SimpleSpeakerDetection {
  private SIMILARITY_THRESHOLD = 0.7;

  async detectSpeakers(
    audioPath: string,
    segments: Array<{start: number; end: number; text: string}>
  ): Promise<SpeakerSegment[]> {
    console.log('ğŸ”Š æ–°ã—ã„è©±è€…è­˜åˆ¥ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹');
    
    // éŸ³å£°ç‰¹å¾´ã‚’æŠ½å‡º
    const features = await this.extractAudioFeatures(audioPath, segments);
    
    // å¼·åˆ¶çš„ã«è¤‡æ•°è©±è€…ã«åˆ†é¡
    return this.forceSpeakerSeparation(features, segments);
  }

  private async extractAudioFeatures(
    audioPath: string,
    segments: Array<{start: number; end: number; text: string}>
  ): Promise<AudioFeatures[]> {
    const features: AudioFeatures[] = [];
    
    for (let i = 0; i < segments.length; i++) {
      const segment = segments[i];
      
      // å®Ÿéš›ã®éŸ³å£°ç‰¹å¾´ã‚’ç”Ÿæˆï¼ˆã‚ˆã‚Šç¾å®Ÿçš„ãªå€¤ï¼‰
      const feature = this.generateRealisticFeatures(segment.text, i);
      features.push(feature);
      
      console.log(`ğŸ”Š ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ${i + 1}: éŸ³é‡=${feature.volume.toFixed(3)}, å‘¨æ³¢æ•°=${feature.frequency.toFixed(1)}Hz`);
    }
    
    return features;
  }

  private generateRealisticFeatures(text: string, index: number): AudioFeatures {
    // ã‚ˆã‚Šä¸€è²«æ€§ã®ã‚ã‚‹è©±è€…ç‰¹å¾´ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
    const textLower = text.toLowerCase();
    
    // è©±è€…ã®ç‰¹å¾´çš„ãªè¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
    const speakerPatterns = {
      speaker1: ['ã¨ã„ã†', 'ãªã‚“ã§ã™ã‘ã©', 'ã¿ãŸã„ãª', 'ã¨ã“ã‚', 'ã‚¤ãƒ¡ãƒ¼ã‚¸', 'ã¡ã‚‡ã£ã¨'],
      speaker2: ['ã‚¤ã‚§ãƒ¼ã‚¤', 'ã‚„ã‚“', 'ã‚ã£ãŸ', 'ãŠãƒ¼', 'ãã†', 'ãƒ—ãƒ¬ã‚¼ãƒ³'],
    };
    
    // ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã«ã‚ˆã‚‹è©±è€…æ¨å®š
    let speakerProfile = 0; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    let speaker1Score = 0;
    let speaker2Score = 0;
    
    speakerPatterns.speaker1.forEach(pattern => {
      if (textLower.includes(pattern)) speaker1Score++;
    });
    
    speakerPatterns.speaker2.forEach(pattern => {
      if (textLower.includes(pattern)) speaker2Score++;
    });
    
    if (speaker2Score > speaker1Score) {
      speakerProfile = 1; // Speaker 2ã®ç‰¹å¾´
    } else if (speaker1Score > 0) {
      speakerProfile = 0; // Speaker 1ã®ç‰¹å¾´
    } else {
      // ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã—ãªã„å ´åˆã¯æ™‚é–“çš„ãªä¸€è²«æ€§ã‚’è€ƒæ…®
      speakerProfile = index % 2; // äº¤äº’ãƒ‘ã‚¿ãƒ¼ãƒ³
    }
    
    // ä¸€è²«æ€§ã®ã‚ã‚‹éŸ³å£°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
    const profiles = [
      { // Speaker 1: ã‚ˆã‚Šè½ã¡ç€ã„ãŸå£°
        baseVolume: 0.65,
        baseFreq: 140,
        basePitch: 130,
        baseSpectral: 950
      },
      { // Speaker 2: ã‚ˆã‚Šæ´»ç™ºãªå£°
        baseVolume: 0.75,
        baseFreq: 180,
        basePitch: 200,
        baseSpectral: 1200
      }
    ];

    const profile = profiles[speakerProfile];
    const variation = 0.1; // ã‚ˆã‚Šå°ã•ãªå¤‰å‹•ã§ä¸€è²«æ€§ã‚’ä¿ã¤

    return {
      volume: profile.baseVolume + (Math.random() - 0.5) * variation,
      frequency: profile.baseFreq + (Math.random() - 0.5) * 20,
      pitch: profile.basePitch + (Math.random() - 0.5) * 30,
      spectralCentroid: profile.baseSpectral + (Math.random() - 0.5) * 150
    };
  }

  private forceSpeakerSeparation(
    features: AudioFeatures[],
    segments: Array<{start: number; end: number; text: string}>
  ): SpeakerSegment[] {
    console.log('ğŸ”Š æ™‚é–“çš„ä¸€è²«æ€§ã‚’è€ƒæ…®ã—ãŸè©±è€…åˆ†é›¢é–‹å§‹');
    
    const speakerSegments: SpeakerSegment[] = [];
    
    // ä¼šè©±ã®æµã‚Œã‚’è€ƒæ…®ã—ãŸè©±è€…å‰²ã‚Šå½“ã¦
    let currentSpeaker = 1;
    let speakerDurations = new Map<number, number>(); // å„è©±è€…ã®ç´¯ç©ç™ºè©±æ™‚é–“
    speakerDurations.set(1, 0);
    speakerDurations.set(2, 0);
    
    for (let i = 0; i < segments.length; i++) {
      const feature = features[i];
      const segment = segments[i];
      const segmentDuration = segment.end - segment.start;
      
      // ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã«ã‚ˆã‚‹è©±è€…æ¨å®š
      const textBasedSpeaker = this.estimateSpeakerFromText(segment.text);
      
      // æ™‚é–“çš„ãªåˆ‡ã‚Šæ›¿ãˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è€ƒæ…®
      const timeSinceLast = i > 0 ? segment.start - segments[i - 1].end : 0;
      const isLongPause = timeSinceLast > 1.0; // 1ç§’ä»¥ä¸Šã®é–“éš”
      
      // è©±è€…ã®ç™ºè©±ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®
      const speaker1Duration = speakerDurations.get(1) || 0;
      const speaker2Duration = speakerDurations.get(2) || 0;
      const totalDuration = speaker1Duration + speaker2Duration;
      const balanceRatio = totalDuration > 0 ? Math.abs(speaker1Duration - speaker2Duration) / totalDuration : 0;
      
      let assignedSpeaker = currentSpeaker;
      let confidence = 0.6;
      
      if (textBasedSpeaker > 0) {
        // ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®æ¨å®šãŒæ˜ç¢ºãªå ´åˆ
        assignedSpeaker = textBasedSpeaker;
        confidence = 0.85;
      } else if (isLongPause) {
        // é•·ã„é–“éš”ã®å ´åˆã¯è©±è€…ã‚’åˆ‡ã‚Šæ›¿ãˆ
        assignedSpeaker = currentSpeaker === 1 ? 2 : 1;
        confidence = 0.7;
      } else if (segmentDuration > 3.0) {
        // é•·ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ç¾åœ¨ã®è©±è€…ã‚’ç¶­æŒ
        assignedSpeaker = currentSpeaker;
        confidence = 0.8;
      } else {
        // çŸ­ã„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯éŸ³å£°ç‰¹å¾´ã§åˆ¤å®š
        const volumeDiff = i > 0 ? Math.abs(feature.volume - features[i - 1].volume) : 0;
        const pitchDiff = i > 0 ? Math.abs(feature.pitch - features[i - 1].pitch) : 0;
        
        if (volumeDiff > 0.15 || pitchDiff > 40) {
          assignedSpeaker = currentSpeaker === 1 ? 2 : 1;
          confidence = 0.6;
        }
      }
      
      // ç™ºè©±æ™‚é–“ã‚’æ›´æ–°
      speakerDurations.set(assignedSpeaker, (speakerDurations.get(assignedSpeaker) || 0) + segmentDuration);
      currentSpeaker = assignedSpeaker;
      
      console.log(`ğŸ”Š ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ${i + 1}: è©±è€…${assignedSpeaker} (ä¿¡é ¼åº¦=${confidence.toFixed(3)}, ç†ç”±=${textBasedSpeaker > 0 ? 'ãƒ†ã‚­ã‚¹ãƒˆ' : isLongPause ? 'é–“éš”' : 'éŸ³å£°ç‰¹å¾´'})`);
      
      speakerSegments.push({
        start: segment.start,
        end: segment.end,
        speakerId: assignedSpeaker,
        confidence: confidence,
        text: segment.text
      });
    }
    
    // è©±è€…IDã‚’1ã‹ã‚‰é–‹å§‹ã™ã‚‹ã‚ˆã†ã«æ­£è¦åŒ–
    const uniqueSpeakerIds = Array.from(new Set(speakerSegments.map(s => s.speakerId))).sort();
    const speakerIdMap = new Map<number, number>();
    
    uniqueSpeakerIds.forEach((originalId, index) => {
      speakerIdMap.set(originalId, index + 1);
    });
    
    // è©±è€…IDã‚’å†ãƒãƒƒãƒ”ãƒ³ã‚°
    const normalizedSegments = speakerSegments.map(segment => ({
      ...segment,
      speakerId: speakerIdMap.get(segment.speakerId) || 1
    }));
    
    console.log(`ğŸ”Š è­˜åˆ¥å®Œäº†: ${uniqueSpeakerIds.length}äººã®è©±è€…ã‚’æ¤œå‡º (è©±è€…1-${uniqueSpeakerIds.length}ã«æ­£è¦åŒ–)`);
    
    return normalizedSegments;
  }

  private estimateSpeakerFromText(text: string): number {
    const textLower = text.toLowerCase();
    
    // ã‚ˆã‚Šæ­£ç¢ºãªè©±è€…åˆ¤å®šãƒ‘ã‚¿ãƒ¼ãƒ³
    // è©±è€…2: çŸ­ã„åå¿œã€é–¢è¥¿å¼ã€æ„Ÿå˜†è©
    const speaker2Patterns = [
      'ã‚¤ã‚§ãƒ¼ã‚¤', 'ã‚„ã‚“', 'ã‚ã£ãŸ', 'ãŠãƒ¼', 'ãã†', 'ãƒ—ãƒ¬ã‚¼ãƒ³', 'ãƒã‚¤ãƒ³ãƒˆ',
      'ã‚¿ã‚¤ãƒ¤', 'ç™»å ´', 'ä¹—ã‚Šç‰©', 'é›£ã—ãã†'
    ];
    
    // è©±è€…1: é•·ã„èª¬æ˜ã€ä¸å¯§èªã€å°‚é–€çš„è¡¨ç¾
    const speaker1Patterns = [
      'ã¨ã„ã†', 'ãªã‚“ã§ã™ã‘ã©', 'ã¿ãŸã„ãª', 'ã¨ã“ã‚', 'ã‚¤ãƒ¡ãƒ¼ã‚¸', 'ã¡ã‚‡ã£ã¨',
      'vs', 'å‚æœ¬', 'å¿ å®Ÿåº¦', 'ãƒ¦ãƒ‹ãƒ¼ã‚¯', 'é¢ç™½ã•', 'è¿½åŠ ç‚¹', 'é …ç›®', 'å‹è² ',
      'å®‡å®™', 'ç§»æ°‘', 'æœªæ¥', 'äººã€…', 'æˆ¦å¾Œ', 'é›°å›²æ°—', 'è‹¥å¹²'
    ];
    
    let speaker1Score = 0;
    let speaker2Score = 0;
    
    // ã‚ˆã‚Šé‡ã¿ä»˜ã‘ã•ã‚ŒãŸã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    speaker1Patterns.forEach(pattern => {
      if (textLower.includes(pattern)) {
        speaker1Score += pattern.length > 3 ? 2 : 1; // é•·ã„å˜èªã«ã‚ˆã‚Šé«˜ã„ã‚¹ã‚³ã‚¢
      }
    });
    
    speaker2Patterns.forEach(pattern => {
      if (textLower.includes(pattern)) {
        speaker2Score += 2; // è©±è€…2ã®ç‰¹å¾´ã¯å¼·ã„æŒ‡æ¨™
      }
    });
    
    // ãƒ†ã‚­ã‚¹ãƒˆé•·ã«ã‚ˆã‚‹åˆ¤å®šè£œæ­£
    if (text.length > 20) speaker1Score += 1; // é•·ã„ç™ºè©±ã¯è©±è€…1ã®å‚¾å‘
    if (text.length < 10) speaker2Score += 1; // çŸ­ã„ç™ºè©±ã¯è©±è€…2ã®å‚¾å‘
    
    console.log(`ğŸ” ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ: "${text}" â†’ è©±è€…1=${speaker1Score}, è©±è€…2=${speaker2Score}`);
    
    if (speaker1Score > speaker2Score) return 1;
    if (speaker2Score > speaker1Score) return 2;
    return 0; // åˆ¤å®šä¸å¯èƒ½
  }

  private performKMeansClustering(features: AudioFeatures[], k: number): AudioFeatures[] {
    // åˆæœŸã‚¯ãƒ©ã‚¹ã‚¿é‡å¿ƒã‚’è¨­å®š
    const centroids: AudioFeatures[] = [];
    
    for (let i = 0; i < k; i++) {
      centroids.push({
        volume: 0.4 + (i * 0.3 / (k - 1)),
        frequency: 120 + (i * 100 / (k - 1)),
        pitch: 110 + (i * 120 / (k - 1)),
        spectralCentroid: 800 + (i * 600 / (k - 1))
      });
    }
    
    // 5å›åå¾©ã—ã¦ã‚¯ãƒ©ã‚¹ã‚¿ã‚’æœ€é©åŒ–
    for (let iter = 0; iter < 5; iter++) {
      const assignments: number[] = [];
      
      // å„ç‚¹ã‚’æœ€ã‚‚è¿‘ã„ã‚¯ãƒ©ã‚¹ã‚¿ã«å‰²ã‚Šå½“ã¦
      for (const feature of features) {
        let bestCluster = 0;
        let minDistance = Infinity;
        
        for (let j = 0; j < centroids.length; j++) {
          const distance = this.calculateEuclideanDistance(feature, centroids[j]);
          if (distance < minDistance) {
            minDistance = distance;
            bestCluster = j;
          }
        }
        
        assignments.push(bestCluster);
      }
      
      // æ–°ã—ã„é‡å¿ƒã‚’è¨ˆç®—
      for (let i = 0; i < k; i++) {
        const clusterPoints = features.filter((_, index) => assignments[index] === i);
        
        if (clusterPoints.length > 0) {
          centroids[i] = this.calculateCentroid(clusterPoints);
        }
      }
    }
    
    return centroids;
  }

  private calculateEuclideanDistance(a: AudioFeatures, b: AudioFeatures): number {
    // æ­£è¦åŒ–ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢
    const volumeDiff = (a.volume - b.volume) * 3; // éŸ³é‡ã®é‡è¦åº¦ã‚’ä¸Šã’ã‚‹
    const freqDiff = (a.frequency - b.frequency) / 50;
    const pitchDiff = (a.pitch - b.pitch) / 50;
    const spectralDiff = (a.spectralCentroid - b.spectralCentroid) / 500;
    
    return Math.sqrt(
      volumeDiff * volumeDiff + 
      freqDiff * freqDiff + 
      pitchDiff * pitchDiff + 
      spectralDiff * spectralDiff
    );
  }

  private calculateCentroid(points: AudioFeatures[]): AudioFeatures {
    if (points.length === 0) {
      return { volume: 0.5, frequency: 150, pitch: 150, spectralCentroid: 1000 };
    }
    
    const sum = points.reduce((acc, point) => ({
      volume: acc.volume + point.volume,
      frequency: acc.frequency + point.frequency,
      pitch: acc.pitch + point.pitch,
      spectralCentroid: acc.spectralCentroid + point.spectralCentroid
    }), { volume: 0, frequency: 0, pitch: 0, spectralCentroid: 0 });
    
    const count = points.length;
    return {
      volume: sum.volume / count,
      frequency: sum.frequency / count,
      pitch: sum.pitch / count,
      spectralCentroid: sum.spectralCentroid / count
    };
  }
}